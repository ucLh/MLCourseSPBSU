{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "combined_data_file_name = \"./netflix-prize-data/combined_data_%s.txt\"\n",
    "\n",
    "target_f = open(\"./processed_data.csv\", \"w+\")\n",
    "for i in {1,2,3,4}:\n",
    "    print(\"Data file: \" + str(i) + \"/4\")\n",
    "    \n",
    "    cur_movie_id = None\n",
    "    with open(combined_data_file_name % i) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if (len(row) == 1):\n",
    "                cur_movie_id = row[0][:-1]\n",
    "            else:\n",
    "                user_id = row[0]\n",
    "                rating = row[1]\n",
    "                \n",
    "                target_f.write(user_id + \",\" + rating + \",\" + cur_movie_id + \"\\n\")\n",
    "target_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           User_Id  Rating  Movie_Id\n",
      "0          1488844       3         1\n",
      "5000000     501954       2       996\n",
      "10000000    404654       5      1962\n",
      "15000000    886608       2      2876\n",
      "20000000   1193835       2      3825\n",
      "25000000   1899206       3      4661\n",
      "30000000    154804       4      5496\n",
      "35000000   2078749       5      6274\n",
      "40000000    450763       5      7057\n",
      "45000000    102092       3      7991\n",
      "50000000    220298       5      9023\n",
      "55000000    550530       5     10042\n",
      "60000000    222570       3     11038\n",
      "65000000   1273080       5     11875\n",
      "70000000   2026970       5     12676\n",
      "75000000    506044       4     13582\n",
      "80000000    353605       2     14453\n",
      "85000000    664606       3     15116\n",
      "90000000   2213715       3     16008\n",
      "95000000   1589401       5     16879\n",
      "100000000  2314006       4     17627\n",
      "Shape User-Ratings unfiltered:\t(100480507, 3)\n",
      "Shape User-Ratings filtered:\t(60546559, 3)\n",
      "One-hot user matrix shape: (60546559, 150245)\n",
      "One-hot movie matrix shape: (60546559, 2042)\n",
      "(60546559, 152287)\n",
      "(60546559, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_data():\n",
    "    data_file_path = \"./processed_data.csv\"\n",
    "\n",
    "    df = pd.read_csv(data_file_path, header = None, names = ['User_Id','Rating','Movie_Id'])\n",
    "    print(df.iloc[::5000000, :])\n",
    "    \n",
    "    # Filter really sparse movies and users\n",
    "    min_movie_ratings = 10000\n",
    "    filter_movies = (df['Movie_Id'].value_counts()>min_movie_ratings)\n",
    "    filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "    # Filter sparse users\n",
    "    min_user_ratings = 200\n",
    "    filter_users = (df['User_Id'].value_counts()>min_user_ratings)\n",
    "    filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "    # Actual filtering\n",
    "    df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['User_Id'].isin(filter_users))]\n",
    "    print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "    print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))\n",
    "    del filter_movies, filter_users, min_movie_ratings, min_user_ratings, df\n",
    "    \n",
    "    encoder = OneHotEncoder(categories='auto') \n",
    "\n",
    "    # (number_of_ratings x number_of_users)\n",
    "    one_hot_user_matrix = encoder.fit_transform(np.asarray(df_filterd['User_Id']).reshape(-1,1)) \n",
    "    print(\"One-hot user matrix shape: \" + str(one_hot_user_matrix.shape))\n",
    "    \n",
    "    # (number_of_ratings x number_of_movie_ids)\n",
    "    one_hot_movie_matrix = encoder.fit_transform(np.asarray(df_filterd['Movie_Id']).reshape(-1,1))\n",
    "    print(\"One-hot movie matrix shape: \" + str(one_hot_movie_matrix.shape))\n",
    "    \n",
    "    # train data in CSR format\n",
    "    X = hstack([one_hot_user_matrix, one_hot_movie_matrix]).tocsr()\n",
    "    # data to predict\n",
    "    ratings=np.asarray(df_filterd['Rating']).reshape(-1,1)\n",
    "    \n",
    "    return X,ratings\n",
    "\n",
    "X,ratings = get_data()\n",
    "\n",
    "# do shuffling so records will be evenly distributed over the matrix\n",
    "X,ratings = shuffle(X,ratings)\n",
    "\n",
    "print(X.shape)\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def rmse(y, y_pred):\n",
    "    rmse = np.sqrt(np.sum((y - y_pred) ** 2) / len(y))\n",
    "    return rmse\n",
    "\n",
    "def r2_score(y, y_pred):\n",
    "    mean_y = np.mean(y)\n",
    "    ss_tot = np.sum((y - mean_y) ** 2)\n",
    "    ss_res = np.sum((y - y_pred) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model class\n",
    "class FMModel():\n",
    "    def __init__(self, features_num, k=2, lr=0.1, batch_size=256, num_iters=1500):\n",
    "        np.random.seed(0)  # Set the seed for repeatability\n",
    "        self.lr = lr  # learning rate\n",
    "        self.batch_size = batch_size\n",
    "        self.num_iters = num_iters\n",
    "        self.v = np.random.normal(0, 0.1, size=(features_num, k))\n",
    "        self.w_lin = np.random.normal(0, 0.1, size=(features_num, 1))\n",
    "        self.w_bias = np.array((0,), dtype=np.float32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = np.sum((x.dot(self.v) * x.dot(self.v)), keepdims=True, axis=1)\n",
    "        out_2 = np.sum((x.multiply(x)).dot(self.v * self.v), keepdims=True, axis=1)\n",
    "        out_inter = (out_1 - out_2) / 2\n",
    "        out_linear = x.dot(self.w_lin) + self.w_bias\n",
    "        return out_linear + out_inter\n",
    "    \n",
    "    def calculate_loss(self, x, y):\n",
    "        pred = self.forward(x)\n",
    "        n = len(y)\n",
    "        loss = np.sum((pred - y) ** 2) / n\n",
    "        pred_grad = (pred - y) / n  * 2.0\n",
    "        return loss, pred_grad\n",
    "    \n",
    "    def step(self, x, y):\n",
    "        # Calculate loss\n",
    "        loss, dout = self.calculate_loss(x, y)\n",
    "        \n",
    "        # Calculate grads for a batch\n",
    "        dw_lin = x.T.dot(dout)      \n",
    "        dw_bias = np.sum(dout, axis=0)\n",
    "        \n",
    "        coef = (x.dot(self.v)).T\n",
    "        dv_1 = x.T.dot(coef.T)\n",
    "        dv = 0\n",
    "        for i in range(self.batch_size):\n",
    "            x_ = hstack((x[i, :].T, x[i, :].T))\n",
    "            for j in range(self.v.shape[1]-2):\n",
    "                x_ = hstack((x_, x[i, :].T))\n",
    "            x_2 = x_.multiply(x_)\n",
    "            dv += dv_1 * dout[i] - (x_2.multiply(self.v)).multiply(dout[i])\n",
    "        dv /= self.batch_size\n",
    "        \n",
    "        # Take a step towards negative gradient\n",
    "        self.w_lin -= self.lr * dw_lin\n",
    "        self.w_bias -= self.lr * dw_bias\n",
    "        self.v -= self.lr * dv\n",
    "        \n",
    "    def train(self, x, y):\n",
    "        for i in tqdm(range(self.num_iters)):\n",
    "            # Make a batch from already shuffled data\n",
    "            x_batch = x[i*self.batch_size:(i+1)*self.batch_size, :]\n",
    "            y_batch = y[i*self.batch_size:(i+1)*self.batch_size, :]\n",
    "            if (i % 100 == 0) and (self.lr >= 0.01):\n",
    "                self.lr /= 1.1\n",
    "            self.step(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss: 14.318356676340128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dbd2e9f87845aa91d611fd69353027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE train: 1.0415860754034834\n",
      "RMSE test: 1.041671097965188\n",
      "R2 score train: 0.0053463422604707045\n",
      "R2 score test: 0.005317635843055668\n",
      "Final loss: 1.085078676336\n",
      "Starting loss: 14.319031217329572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa0a610458f40f687c35a2b4a5ee132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE train: 1.0417490475811149\n",
      "RMSE test: 1.041669246180437\n",
      "R2 score train: 0.005077271713272213\n",
      "R2 score test: 0.005152296805631007\n",
      "Final loss: 1.08507481843812\n",
      "Starting loss: 14.316390152059538\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be54782fd2f34bcea6fc05a4b35f5a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE train: 1.0417341494501506\n",
      "RMSE test: 1.041728841137501\n",
      "R2 score train: 0.005109947668328396\n",
      "R2 score test: 0.005021679896495601\n",
      "Final loss: 1.0851989784576808\n",
      "Starting loss: 14.315422406159891\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4941f7f4286b4a53960433560c71fce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE train: 1.0417027025274528\n",
      "RMSE test: 1.0418546199747754\n",
      "R2 score train: 0.005094617401049217\n",
      "R2 score test: 0.005082997316346871\n",
      "Final loss: 1.0854610491627836\n",
      "Starting loss: 14.314165786297808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dca319767cb4214b8a31cda321dd512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE train: 1.0417552828718215\n",
      "RMSE test: 1.0416443027249374\n",
      "R2 score train: 0.0050972151017790734\n",
      "R2 score test: 0.005072517463157955\n",
      "Final loss: 1.085022853399321\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "kf = KFold(shuffle=False, n_splits=5)\n",
    "train_history = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = ratings[train_index]\n",
    "    y_test = ratings[test_index]\n",
    "    model = FMModel(X_train.shape[1])\n",
    "    print(f'Starting loss: {model.calculate_loss(X_test, y_test)[0]}')\n",
    "    \n",
    "    model.train(X_train, y_train)\n",
    "    y_pred = model.forward(X_train)\n",
    "    y_pred_test = model.forward(X_test)\n",
    "    \n",
    "    print(f'RMSE train: {rmse(y_train, y_pred)}')\n",
    "    print(f'RMSE test: {rmse(y_test, y_pred_test)}')\n",
    "    print(f'R2 score train: {r2_score(y_train, y_pred)}')\n",
    "    print(f'R2 score test: {r2_score(y_test, y_pred_test)}')\n",
    "    \n",
    "    history_entry = {'rmse_train': rmse(y_train, y_pred),\n",
    "                     'rmse_test': rmse(y_test, y_pred_test),\n",
    "                     'r2_train': r2_score(y_train, y_pred),\n",
    "                     'r2_test': r2_score(y_test, y_pred_test),\n",
    "                    }\n",
    "    train_history.append(history_entry)\n",
    "    print(f'Final loss: {model.calculate_loss(X_test, y_test)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for resulting table\n",
    "def mean_std(arr):\n",
    "    return np.mean(arr), np.std(arr)\n",
    "\n",
    "r2_train_all = np.array([entry['r2_train'] for entry in train_history], dtype='float32')\n",
    "r2_test_all = np.array([entry['r2_test'] for entry in train_history], dtype='float32')\n",
    "rmse_train_all = np.array([entry['rmse_train'] for entry in train_history], dtype='float32')\n",
    "rmse_test_all = np.array([entry['rmse_test'] for entry in train_history], dtype='float32')\n",
    "\n",
    "r2_train_mean, r2_train_std = mean_std(r2_train_all)\n",
    "r2_test_mean, r2_test_std = mean_std(r2_test_all)\n",
    "rmse_train_mean, rmse_train_std = mean_std(rmse_train_all)\n",
    "rmse_test_mean, rmse_test_std = mean_std(rmse_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create resulting table\n",
    "from prettytable import PrettyTable\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='table.txt', level=logging.INFO)\n",
    "\n",
    "tb = PrettyTable()\n",
    "tb.field_names = ['', 'T1', 'T2', 'T3', 'T4', 'T5', 'E', 'STD']\n",
    "tb.add_row(['r2_train'] + r2_train_all.tolist() + [r2_train_mean, r2_train_std])\n",
    "tb.add_row(['r2_test'] + r2_test_all.tolist() + [r2_test_mean, r2_test_std])\n",
    "tb.add_row(['rmse_train'] + rmse_train_all.tolist() + [rmse_train_mean, rmse_train_std])\n",
    "tb.add_row(['rmse_test'] + rmse_test_all.tolist() + [rmse_test_mean, rmse_test_std])\n",
    "\n",
    "logging.info(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
